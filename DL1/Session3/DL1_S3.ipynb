{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f653dccc274c4ef4b5b2cd0f3b9a50b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2573c125e0b4016951dd0f207f6fa52",
              "IPY_MODEL_795bdb569c1e408ba6ad17d0af162d6b",
              "IPY_MODEL_353fc9a7b72843b091ea1b0276df84fb"
            ],
            "layout": "IPY_MODEL_4a057bff7b544595861ed40f99712a64"
          }
        },
        "f2573c125e0b4016951dd0f207f6fa52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ade56010c68f46ec82b89e7e992968fd",
            "placeholder": "​",
            "style": "IPY_MODEL_b9adadfa819c44f78d78604b63ea3544",
            "value": "Map: 100%"
          }
        },
        "795bdb569c1e408ba6ad17d0af162d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c3b0bda95b4403b8002638d37fafc9",
            "max": 29652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_532d4847e6a74442b81c39f83f62ad95",
            "value": 29652
          }
        },
        "353fc9a7b72843b091ea1b0276df84fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d24e8f4e3614b9f81ecd6f6d0135412",
            "placeholder": "​",
            "style": "IPY_MODEL_689a686fd698471bac3bf346d90da6ff",
            "value": " 29652/29652 [00:55&lt;00:00, 979.77 examples/s]"
          }
        },
        "4a057bff7b544595861ed40f99712a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade56010c68f46ec82b89e7e992968fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9adadfa819c44f78d78604b63ea3544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21c3b0bda95b4403b8002638d37fafc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532d4847e6a74442b81c39f83f62ad95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d24e8f4e3614b9f81ecd6f6d0135412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689a686fd698471bac3bf346d90da6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6085af6122f646d4a32d51e8377961c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4709e8804b9f4ce08eb2110f65528ca4",
              "IPY_MODEL_bf14379e64fb40b5af607b16a8e4694b",
              "IPY_MODEL_49062733a9054bd18bbffa59d7a4e735"
            ],
            "layout": "IPY_MODEL_bf86607a25dd46d09b3367c7589e3ff2"
          }
        },
        "4709e8804b9f4ce08eb2110f65528ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3265272ee04f659c3d229e4e757b0a",
            "placeholder": "​",
            "style": "IPY_MODEL_04f7f742c8e84339ae5d36fd361baff5",
            "value": "Map: 100%"
          }
        },
        "bf14379e64fb40b5af607b16a8e4694b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf784cda2fb4d3a968b63a9a759bfe0",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b8fa056da8c49adbb8a80a185e495af",
            "value": 20
          }
        },
        "49062733a9054bd18bbffa59d7a4e735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62089e3fe02e4f8badcd4d2dac74e958",
            "placeholder": "​",
            "style": "IPY_MODEL_f7696cc5df4f48ae91169fed141c001c",
            "value": " 20/20 [00:00&lt;00:00, 281.50 examples/s]"
          }
        },
        "bf86607a25dd46d09b3367c7589e3ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3265272ee04f659c3d229e4e757b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04f7f742c8e84339ae5d36fd361baff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf784cda2fb4d3a968b63a9a759bfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8fa056da8c49adbb8a80a185e495af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62089e3fe02e4f8badcd4d2dac74e958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7696cc5df4f48ae91169fed141c001c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7abde019f2ff4eea975109d77d726b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a3b20bb1028496eb6f7861f0e5ee5a7",
              "IPY_MODEL_adc62ec5581949d5828940dc84c75af7",
              "IPY_MODEL_e2c990d76f5c42d494a5927525c5f40f"
            ],
            "layout": "IPY_MODEL_319e5f891f984ea48d9a97e420f65550"
          }
        },
        "5a3b20bb1028496eb6f7861f0e5ee5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abd7305bccda4823a7267a6d4eab04f2",
            "placeholder": "​",
            "style": "IPY_MODEL_3b17df2ef780453eb5cdc2969b0d1bb2",
            "value": "Map: 100%"
          }
        },
        "adc62ec5581949d5828940dc84c75af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16c5c45ccdd34c87bd1bd8be86cc04a7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_986ff54f69f14b8098f91f0ca144cbd9",
            "value": 1
          }
        },
        "e2c990d76f5c42d494a5927525c5f40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6e4e8a422745efac027b7cc8549249",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d7aff0f8d647d88ed9758968819815",
            "value": " 1/1 [00:01&lt;00:00,  1.40s/ examples]"
          }
        },
        "319e5f891f984ea48d9a97e420f65550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abd7305bccda4823a7267a6d4eab04f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b17df2ef780453eb5cdc2969b0d1bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c5c45ccdd34c87bd1bd8be86cc04a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986ff54f69f14b8098f91f0ca144cbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb6e4e8a422745efac027b7cc8549249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d7aff0f8d647d88ed9758968819815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K8A_Vg81du5",
        "outputId": "cc06208e-abe3-43e6-99fd-6aa5e6325391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep  8 06:23:55 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0              31W /  70W |  10537MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1im-yxXDXyl",
        "outputId": "35abedcc-c786-4dc6-a984-dd19864b70bb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irWp4KpZ2Co9",
        "outputId": "1e477f2d-de47-4c86-9da1-c689ca87da41"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers==4.19.2\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "8mlE96IP2Mui"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/WikiHow/WikiHow4k.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "anmzzPuZ2VXQ",
        "outputId": "c8165971-9889-459c-bad7-ed32811fedd6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  How to Get Your Horse to Trust You: 20 Helpful...   \n",
              "1  How to Get Your Horse to Trust You: 20 Helpful...   \n",
              "2  How to Get Your Horse to Trust You: 20 Helpful...   \n",
              "3  How to Get Your Horse to Trust You: 20 Helpful...   \n",
              "4  How to Get Your Horse to Trust You: 20 Helpful...   \n",
              "\n",
              "                                             heading  \\\n",
              "0                    Rub all over your horse's body.   \n",
              "1                                  Groom your horse.   \n",
              "2  Use other techniques to touch your horse, such...   \n",
              "3  Pet your horse everyday to establish a closer ...   \n",
              "4                      Place a bridle on your horse.   \n",
              "\n",
              "                                           paragraph  \n",
              "0  Doing this will let the horse know that he can...  \n",
              "1  Like rubbing, grooming shows that you are frie...  \n",
              "2  Before massaging your horse, make sure that he...  \n",
              "3  Like when you build a relationship with anothe...  \n",
              "4  The horse's bridle will need to comfortably pl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad23a2eb-7dda-4387-9a12-be0b2e08e379\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>heading</th>\n",
              "      <th>paragraph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How to Get Your Horse to Trust You: 20 Helpful...</td>\n",
              "      <td>Rub all over your horse's body.</td>\n",
              "      <td>Doing this will let the horse know that he can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How to Get Your Horse to Trust You: 20 Helpful...</td>\n",
              "      <td>Groom your horse.</td>\n",
              "      <td>Like rubbing, grooming shows that you are frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to Get Your Horse to Trust You: 20 Helpful...</td>\n",
              "      <td>Use other techniques to touch your horse, such...</td>\n",
              "      <td>Before massaging your horse, make sure that he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How to Get Your Horse to Trust You: 20 Helpful...</td>\n",
              "      <td>Pet your horse everyday to establish a closer ...</td>\n",
              "      <td>Like when you build a relationship with anothe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Get Your Horse to Trust You: 20 Helpful...</td>\n",
              "      <td>Place a bridle on your horse.</td>\n",
              "      <td>The horse's bridle will need to comfortably pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad23a2eb-7dda-4387-9a12-be0b2e08e379')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad23a2eb-7dda-4387-9a12-be0b2e08e379 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad23a2eb-7dda-4387-9a12-be0b2e08e379');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc05144d-5b38-4efc-a847-2c9994427237\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc05144d-5b38-4efc-a847-2c9994427237')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc05144d-5b38-4efc-a847-2c9994427237 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 61008,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3279,\n        \"samples\": [\n          \"How to Become a Jeopardy Contestant: 12 Steps (with Pictures)\",\n          \"How to Build a Coffee Table (with Pictures) - wikiHow\",\n          \"How to Measure Personal Growth: 15 Steps (with Pictures) - wikiHow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"heading\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 48454,\n        \"samples\": [\n          \"Cook the beef on medium heat until the meat is completely brown.\",\n          \"Talk to your doctor about H2 receptor antagonists.\",\n          \"Pull the laces out of the shoes.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paragraph\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49437,\n        \"samples\": [\n          \"[2] Listen to what girls have to say and avoid dominating the conversation. Conversation between two people is give and take. After you say something, give her a chance to respond. When she is saying something, wait until she finishes speaking to respond. If you are truly listening, your response will be relevant to what she has said and add substance to the conversation. Try to practice active listening, such as by:[3]Using neutral statements to show you are paying attention, such as yes, I see, and uh-huh.Asking probing questions to keep her talking, such as What happened next? How did that make you feel? and What are you going to do now?Restating to ensure you understood what she said, such as by saying, It sounds like you are saying ____. Is that right?\",\n          \"This drill is great for understanding the rhythm of the dolphin kick, while also helping you to time your breathing better.Keeping your arms locked at your sides and your head underwater, propel yourself down the length of the pool using only the dolphin kick.Try to alternate between big kicks and small kicks, as described in the previous section, and to get a feel for the rhythm of the movement.Breathe on every fourth or fifth kick, synchronizing your body movement with your breathing in the way that feels most logical and natural.Once you have developed a greater understanding for the rhythm of the movement, you can add your arms back into the stroke.\",\n          \"Check the branches for thick spots where new buds form. Trim thick, woody branches right above this point. Doing this encourages the plant to grow new branches, which can be helpful if your bush looks a little thin or ragged.[5]Try to trim some of the old branches back every fall so your hydrangea always has fresh growth.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df=df.dropna()\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDuFwMDV3V8F",
        "outputId": "0d5ab124-4d23-4315-a078-146f1dbabd46"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(61008, 3)\n",
            "(60330, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df=df.drop_duplicates()\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td2xgRfK3gVJ",
        "outputId": "3a5e4b17-3cb6-4f36-8b74-390d0bee2d89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60330, 3)\n",
            "(49421, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['length']=df.paragraph.map(lambda x: len(x.split(\" \")))"
      ],
      "metadata": {
        "id": "8ZJbNugy3vLF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numOfWords=df.length\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig=plt.figure(figsize=(5,3))\n",
        "plt.hist(numOfWords.to_numpy(),bins=[0.50,100,200,300,500,1000])\n",
        "plt.title(\"Word count distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "fTw5koH7328b",
        "outputId": "19adb1fb-ae2a-4c3e-cd9a-74a6ac7e07cc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tempDf=df[df.length<=200]\n",
        "tempDf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXuC8W8v4bzT",
        "outputId": "c6fb27f0-99e0-48b6-e1b6-c8b9d06d5ff2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48536, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fEFRSfL4ndS",
        "outputId": "8fbf9ba9-3d0b-429e-f664-2b81d9e3f169"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4fb25bb1f9a942a2e2930029211b4a7deaeb18b62f6e5ce6d59730c90da51373.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/087e8f4306cbf22e21907929074344a3b0a46bd680a118eb6267cd5a2bcec5b2.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/05da652a7fca41c1c18027c1201e473217bb373e370d1283e3de49d5880cbf0c.cb2244924ab24d706b02fd7fcedaea4531566537687a539ebb94db511fd122a0\n",
            "loading file https://huggingface.co/allenai/led-base-16384/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/86288ba22bce9550d76e9b26722ee92ae5921ae9285ccbc2904e9a5ad7199b73.cfc08f03f72cde495bd6b3dd3252bca130b3437de370856d084d1453c58b6fea\n",
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 1024\n",
        "max_output_length = 64\n",
        "batch_size = 16\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "    inputs = tokenizer(\n",
        "        batch[\"paragraph\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_input_length\n",
        "    )\n",
        "    outputs = tokenizer(\n",
        "        batch[\"heading\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_output_length\n",
        "    )\n",
        "\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "\n",
        "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"])*[\n",
        "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
        "    ]\n",
        "\n",
        "    batch[\"global_attention_mask\"][0][0] = 1\n",
        "    batch[\"labels\"] = outputs.input_ids\n",
        "\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        for labels in batch[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "ykme3SGH6IhB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "train, validate,test = np.split(tempDf.sample(frac=1,random_state=42),[int(.6*len(df)),int(.7*len(df))])\n",
        "print(train.shape)\n",
        "print(validate.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xixneZQL7Jj5",
        "outputId": "6600277d-9ec5-439a-f945-00ff0f16b53f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29652, 4)\n",
            "(4942, 4)\n",
            "(13942, 4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate=validate[:20]"
      ],
      "metadata": {
        "id": "RkvtkmvO7-vK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVXpaoEY8DJC",
        "outputId": "210df337-9d0e-4a37-e003-eba1af914c55"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_dataset = Dataset.from_pandas(train)\n",
        "val_dataset = Dataset.from_pandas(validate)"
      ],
      "metadata": {
        "id": "qn6Zx9gK8Zro"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"title\", \"heading\", \"paragraph\", \"length\", \"__index_level_0__\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f653dccc274c4ef4b5b2cd0f3b9a50b5",
            "f2573c125e0b4016951dd0f207f6fa52",
            "795bdb569c1e408ba6ad17d0af162d6b",
            "353fc9a7b72843b091ea1b0276df84fb",
            "4a057bff7b544595861ed40f99712a64",
            "ade56010c68f46ec82b89e7e992968fd",
            "b9adadfa819c44f78d78604b63ea3544",
            "21c3b0bda95b4403b8002638d37fafc9",
            "532d4847e6a74442b81c39f83f62ad95",
            "5d24e8f4e3614b9f81ecd6f6d0135412",
            "689a686fd698471bac3bf346d90da6ff"
          ]
        },
        "id": "8h3nZ2Nx86aj",
        "outputId": "d1ce4263-e075-4968-9bac-52dd60b29c1a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/29652 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f653dccc274c4ef4b5b2cd0f3b9a50b5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = val_dataset.map(\n",
        "    process_data_to_model_inputs,\n",
        "    batched=True,\n",
        "    batch_size=batch_size,\n",
        "    remove_columns=[\"title\", \"heading\", \"paragraph\", \"length\", \"__index_level_0__\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6085af6122f646d4a32d51e8377961c7",
            "4709e8804b9f4ce08eb2110f65528ca4",
            "bf14379e64fb40b5af607b16a8e4694b",
            "49062733a9054bd18bbffa59d7a4e735",
            "bf86607a25dd46d09b3367c7589e3ff2",
            "7d3265272ee04f659c3d229e4e757b0a",
            "04f7f742c8e84339ae5d36fd361baff5",
            "1cf784cda2fb4d3a968b63a9a759bfe0",
            "6b8fa056da8c49adbb8a80a185e495af",
            "62089e3fe02e4f8badcd4d2dac74e958",
            "f7696cc5df4f48ae91169fed141c001c"
          ]
        },
        "id": "T-VixyLh9HGW",
        "outputId": "048619e2-3e09-43df-8a2b-c7fbf72134c4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6085af6122f646d4a32d51e8377961c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
        ")\n",
        "val_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
        ")"
      ],
      "metadata": {
        "id": "6hN-5hUX9O2I"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)\n",
        "\n",
        "led.config.num_beams = 2\n",
        "led.config.max_length = 64\n",
        "led.config.min_length = 2\n",
        "led.config.length_penalty = 2.0\n",
        "led.config.early_stopping = True\n",
        "led.config.no_repeat_ngram_size = 3\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokent=True)\n",
        "    labels_ids [labels_ids == -100]=  tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_takens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(\n",
        "        predictions=pred_str,\n",
        "        references=label_str,\n",
        "        rouge_types=[\"rouge2\"]\n",
        "    )[\"rouge2\"].mid\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4)\n",
        "    }\n",
        "\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_info()\n",
        "\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    output_dir=\"./\",\n",
        "    logging_steps=5,\n",
        "    eval_steps=10,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKnRj9I--ElX",
        "outputId": "3e37ab54-c108-4c6b-f319-5b9e90f63979"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/allenai/led-base-16384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ec844bead6f5bbcd6ac727b57e595c2ba40b0970f91cb923423773f72fe1702f.898baac75d55d484b1b1de95b8ab791987c78591acf36ce6131b56d0d2d26af7\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": true,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/allenai/led-base-16384/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c8f7e4603efbc329ce921b34057d78880dead50f45b2a1648b3a06ca6eb17f51.201222b06d46289037a8dccc57548abc8eb81ba042d3762214ac15c9691ff8c7\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "All model checkpoint weights were used when initializing LEDForConditionalGeneration.\n",
            "\n",
            "All the weights of LEDForConditionalGeneration were initialized from the model checkpoint at allenai/led-base-16384.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LEDForConditionalGeneration for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer= Seq2SeqTrainer(\n",
        "    model=led,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "m22nwshYAbka"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G6CgBVyvAzEP",
        "outputId": "b505ddb3-4c0c-41f6-9623-42c163aa1152"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 29652\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 4630\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='4630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 108/4630 51:50 < 36:51:51, 0.03 it/s, Epoch 0.23/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge2 Precision</th>\n",
              "      <th>Rouge2 Recall</th>\n",
              "      <th>Rouge2 Fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.117400</td>\n",
              "      <td>1.720761</td>\n",
              "      <td>0.851100</td>\n",
              "      <td>0.856800</td>\n",
              "      <td>0.853500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.119000</td>\n",
              "      <td>1.641252</td>\n",
              "      <td>0.846500</td>\n",
              "      <td>0.851300</td>\n",
              "      <td>0.848700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.103500</td>\n",
              "      <td>1.602278</td>\n",
              "      <td>0.841900</td>\n",
              "      <td>0.850700</td>\n",
              "      <td>0.846300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.109400</td>\n",
              "      <td>1.633907</td>\n",
              "      <td>0.854100</td>\n",
              "      <td>0.862200</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.992500</td>\n",
              "      <td>1.603565</td>\n",
              "      <td>0.861600</td>\n",
              "      <td>0.864500</td>\n",
              "      <td>0.863100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.052000</td>\n",
              "      <td>1.618533</td>\n",
              "      <td>0.839600</td>\n",
              "      <td>0.845100</td>\n",
              "      <td>0.842400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.097900</td>\n",
              "      <td>1.628273</td>\n",
              "      <td>0.850500</td>\n",
              "      <td>0.857200</td>\n",
              "      <td>0.853600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.014700</td>\n",
              "      <td>1.602072</td>\n",
              "      <td>0.848300</td>\n",
              "      <td>0.856500</td>\n",
              "      <td>0.852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.956300</td>\n",
              "      <td>1.591976</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.855600</td>\n",
              "      <td>0.852500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.955800</td>\n",
              "      <td>1.641683</td>\n",
              "      <td>0.849600</td>\n",
              "      <td>0.856100</td>\n",
              "      <td>0.852700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-10\n",
            "Configuration saved in ./checkpoint-10/config.json\n",
            "Model weights saved in ./checkpoint-10/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-10/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-10/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-20\n",
            "Configuration saved in ./checkpoint-20/config.json\n",
            "Model weights saved in ./checkpoint-20/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-20/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-20/special_tokens_map.json\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-30\n",
            "Configuration saved in ./checkpoint-30/config.json\n",
            "Model weights saved in ./checkpoint-30/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-30/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-30/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-10] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-40\n",
            "Configuration saved in ./checkpoint-40/config.json\n",
            "Model weights saved in ./checkpoint-40/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-40/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-40/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-20] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-50\n",
            "Configuration saved in ./checkpoint-50/config.json\n",
            "Model weights saved in ./checkpoint-50/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-50/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-50/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-30] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-60\n",
            "Configuration saved in ./checkpoint-60/config.json\n",
            "Model weights saved in ./checkpoint-60/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-60/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-60/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-40] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-70\n",
            "Configuration saved in ./checkpoint-70/config.json\n",
            "Model weights saved in ./checkpoint-70/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-70/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-70/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-50] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-80\n",
            "Configuration saved in ./checkpoint-80/config.json\n",
            "Model weights saved in ./checkpoint-80/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-80/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-80/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-60] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-90\n",
            "Configuration saved in ./checkpoint-90/config.json\n",
            "Model weights saved in ./checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-70] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./checkpoint-100\n",
            "Configuration saved in ./checkpoint-100/config.json\n",
            "Model weights saved in ./checkpoint-100/pytorch_model.bin\n",
            "tokenizer config file saved in ./checkpoint-100/tokenizer_config.json\n",
            "Special tokens file saved in ./checkpoint-100/special_tokens_map.json\n",
            "Deleting older checkpoint [checkpoint-80] due to args.save_total_limit\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         )\n\u001b[0;32m-> 1317\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2201\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sample_paragraph =\"The reason why I loved the top-down culture at Apple is that important decisions are taken faster. Having an expert giving you green light or not keeps the momentum. How many times in a bottom-up culture do we spend weeks and weeks, sometimes even months, trying to get alignment with +10 people, because every single person needs to agree with the point of view? It is exhausting. So again, my experience is that having that one leader to look up to to help guide decisions is time-saving, it helps us focus on the design craft, instead of project management.\"\n",
        "data=[sample_paragraph]\n",
        "df=pd.DataFrame(data,columns=['paragraph'])\n",
        "df['paragraph'][0]\n",
        "from datasets import Dataset\n",
        "df_test=Dataset.from_pandas(df)\n",
        "df_test"
      ],
      "metadata": {
        "id": "T-lVysJVAfXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac392c3b-9ce1-48e6-ed03-d31ed0b9422f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['paragraph'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import torch\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load tokenizer and model for LED\n",
        "tokenizer = LEDTokenizer.from_pretrained(\"/content/checkpoint-100\")\n",
        "model = LEDForConditionalGeneration.from_pretrained(\"/content/checkpoint-100\").to(\"cuda\").half()\n",
        "\n",
        "# Load tokenizer and model for summarization\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "summarizer_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "summarizer_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn').to(\"cuda\").half()\n",
        "\n",
        "def summarize_paragraph(paragraph):\n",
        "    inputs = summarizer_tokenizer(paragraph, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = summarizer_model.generate(inputs['input_ids'].to(\"cuda\"), max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def generate_tags(paragraph):\n",
        "    vectorizer = CountVectorizer(stop_words='english', max_features=5)\n",
        "    X = vectorizer.fit_transform([paragraph])\n",
        "    features = vectorizer.get_feature_names_out()\n",
        "    return features\n",
        "\n",
        "def generate_answer(batch):\n",
        "    inputs_dict = tokenizer(batch[\"paragraph\"], padding=\"max_length\", max_length=512, return_tensors=\"pt\", truncation=True)\n",
        "    input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
        "    global_attention_mask = torch.zeros_like(attention_mask).to(\"cuda\")\n",
        "\n",
        "    predicted_heading_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
        "    batch[\"generated_heading\"] = tokenizer.batch_decode(predicted_heading_ids, skip_special_tokens=True)\n",
        "\n",
        "    #Generating summary\n",
        "    summaries = [summarize_paragraph(text) for text in batch[\"paragraph\"]]\n",
        "    batch[\"generated_summary\"] = summaries\n",
        "\n",
        "    #Generating tags\n",
        "    tags = [generate_tags(text) for text in batch[\"paragraph\"]]\n",
        "    batch[\"generated_tags\"] = tags\n",
        "\n",
        "    return batch\n",
        "\n",
        "data = [\"The reason why I loved the top-down culture at Apple is that important decisions are taken faster. Having an expert giving you green light or not keeps the momentum. How many times in a bottom-up culture do we spend weeks and weeks, sometimes even months, trying to get alignment with +10 people, because every single person needs to agree with the point of view? It is exhausting. So again, my experience is that having that one leader to look up to to help guide decisions is time-saving, it helps us focus on the design craft, instead of project management.\"]\n",
        "df_test = pd.DataFrame(data, columns=['paragraph'])\n",
        "df_test = Dataset.from_pandas(df_test)\n",
        "\n",
        "result = df_test.map(generate_answer, batched=True, batch_size=2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7abde019f2ff4eea975109d77d726b44",
            "5a3b20bb1028496eb6f7861f0e5ee5a7",
            "adc62ec5581949d5828940dc84c75af7",
            "e2c990d76f5c42d494a5927525c5f40f",
            "319e5f891f984ea48d9a97e420f65550",
            "abd7305bccda4823a7267a6d4eab04f2",
            "3b17df2ef780453eb5cdc2969b0d1bb2",
            "16c5c45ccdd34c87bd1bd8be86cc04a7",
            "986ff54f69f14b8098f91f0ca144cbd9",
            "fb6e4e8a422745efac027b7cc8549249",
            "d8d7aff0f8d647d88ed9758968819815"
          ]
        },
        "id": "7gPFY2tEOFKN",
        "outputId": "8379b156-5508-4a7c-a2aa-a64f730b89ad"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file /content/checkpoint-100/added_tokens.json. We won't load it.\n",
            "loading file /content/checkpoint-100/vocab.json\n",
            "loading file /content/checkpoint-100/merges.txt\n",
            "loading file None\n",
            "loading file /content/checkpoint-100/special_tokens_map.json\n",
            "loading file /content/checkpoint-100/tokenizer_config.json\n",
            "loading configuration file /content/checkpoint-100/config.json\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"allenai/led-base-16384\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"max_length\": 64,\n",
            "  \"min_length\": 2,\n",
            "  \"model_type\": \"led\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 2,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file /content/checkpoint-100/pytorch_model.bin\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
            "All model checkpoint weights were used when initializing LEDForConditionalGeneration.\n",
            "\n",
            "All the weights of LEDForConditionalGeneration were initialized from the model checkpoint at /content/checkpoint-100.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LEDForConditionalGeneration for predictions without further training.\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"facebook/bart-large-cnn\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n",
            "Model config BartConfig {\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"force_bos_token_to_be_generated\": true,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 142,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_length\": 56,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"prefix\": \" \",\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.19.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7abde019f2ff4eea975109d77d726b44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Generated Headings:\", result[\"generated_heading\"])\n",
        "print(\"Generated Summaries:\", result[\"generated_summary\"])\n",
        "print(\"Generated Tags:\", result[\"generated_tags\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojBT8AM0Psf7",
        "outputId": "ca91f787-4b79-4921-b277-6f7a6ec5deb9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Headings: ['Have a leader to guide you.']\n",
            "Generated Summaries: ['The reason why I loved the top-down culture at Apple is that important decisions are taken faster. Having an expert giving you green light or not keeps the momentum. How many times in a bottom-up culture do we spend weeks and weeks, sometimes even months, trying to get alignment with +10 people?']\n",
            "Generated Tags: [['apple', 'culture', 'decisions', 'having', 'weeks']]\n"
          ]
        }
      ]
    }
  ]
}